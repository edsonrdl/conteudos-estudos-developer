# üìö Guia Completo de Estudos Apache Kafka

## 1. Introdu√ß√£o ao Apache Kafka

### 1.1. O que √© Apache Kafka

- **Defini√ß√£o:** Plataforma distribu√≠da de streaming de eventos
- **Caracter√≠sticas principais:**
    - Sistema de mensageria publish-subscribe
    - Armazenamento dur√°vel de streams de dados
    - Processamento de streams em tempo real
    - Alta taxa de throughput e baixa lat√™ncia
- **Diferencial:** Commit log distribu√≠do e replicado
- **Escala:** Processa trilh√µes de eventos por dia em empresas como LinkedIn

### 1.2. Hist√≥ria e Evolu√ß√£o

- **2010:** Criado no LinkedIn por Jay Kreps, Neha Narkhede e Jun Rao
- **2011:** Open-sourced e doado para Apache Software Foundation
- **2012:** Gradua√ß√£o como projeto top-level Apache
- **2014:** Funda√ß√£o da Confluent pelos criadores originais
- **2019:** Introdu√ß√£o do KRaft (Kafka Raft) para substituir ZooKeeper
- **2021-2024:** Ado√ß√£o massiva em arquiteturas cloud-native e serverless
- **Vers√µes importantes:**
    - 0.8: Replica√ß√£o
    - 0.10: Kafka Streams
    - 2.8: KRaft preview
    - 3.x: Production-ready KRaft

### 1.3. Casos de Uso do Apache Kafka

- **Event Streaming:**
    - Processamento de eventos em tempo real
    - Event sourcing e CQRS
    - Arquiteturas event-driven
- **Integra√ß√£o de Sistemas:**
    - ETL/ELT pipelines
    - Data integration entre microservi√ßos
    - CDC (Change Data Capture)
- **Processamento de Logs:**
    - Agrega√ß√£o centralizada de logs
    - An√°lise e monitoramento em tempo real
    - Auditoria e compliance
- **Microservi√ßos:**
    - Comunica√ß√£o ass√≠ncrona entre servi√ßos
    - Saga pattern para transa√ß√µes distribu√≠das
    - Decoupling de sistemas
- **IoT e Telemetria:**
    - Ingest√£o de dados de sensores
    - Processamento de m√©tricas em escala
- **An√°lise em Tempo Real:**
    - Dashboards real-time
    - Detec√ß√£o de fraudes
    - Recomenda√ß√µes personalizadas

## 2. Arquitetura do Apache Kafka

### 2.1. Componentes Principais

#### 2.1.1. Broker

- **Defini√ß√£o:** Servidor Kafka que armazena e serve dados
- **Responsabilidades:**
    - Receber mensagens de producers
    - Armazenar mensagens em disco
    - Servir mensagens para consumers
    - Participar na replica√ß√£o
- **Caracter√≠sticas:**
    - Identificado por broker.id √∫nico
    - Pode hospedar m√∫ltiplas parti√ß√µes
    - Gerencia leaders e followers
- **Configura√ß√µes importantes:**

properties

```properties
  broker.id=0
  log.dirs=/var/kafka-logs
  num.network.threads=8
  num.io.threads=8
  socket.send.buffer.bytes=102400
  socket.receive.buffer.bytes=102400
```

#### 2.1.2. Topic

- **Defini√ß√£o:** Categoria ou feed name para mensagens
- **Estrutura:**
    - Nome √∫nico no cluster
    - Dividido em parti√ß√µes
    - Configura√ß√µes espec√≠ficas por t√≥pico
- **Naming conventions:**
    - Use lowercase com h√≠fens: `user-events`
    - Evite underscores e caracteres especiais
    - Prefixos por ambiente: `prod.user-events`
- **Configura√ß√µes essenciais:**
    - retention.ms / retention.bytes
    - segment.bytes / segment.ms
    - cleanup.policy (delete/compact)
    - compression.type

#### 2.1.3. Partition

- **Defini√ß√£o:** Unidade de paralelismo e ordena√ß√£o
- **Caracter√≠sticas:**
    - Ordena√ß√£o garantida dentro da parti√ß√£o
    - Distribui√ß√£o por key hash ou round-robin
    - Immutable append-only log
- **Estrutura interna:**
    - Segmentos de log
    - Index files
    - Time index
- **C√°lculo do n√∫mero ideal:**

```
  Parti√ß√µes = max(throughput/producer_rate, throughput/consumer_rate)
```

- **Limites pr√°ticos:**
    - 4000 parti√ß√µes por broker (m√°ximo)
    - 200K parti√ß√µes por cluster

#### 2.1.4. Producer

- **Defini√ß√£o:** Cliente que publica mensagens nos t√≥picos
- **Componentes da mensagem:**
    - Key (opcional)
    - Value
    - Headers
    - Timestamp
    - Partition (calculada ou especificada)
- **Processo de envio:**
    1. Serializa√ß√£o
    2. Particionamento
    3. Batching
    4. Compress√£o
    5. Envio ao broker
- **Garantias de entrega:**
    - At most once (acks=0)
    - At least once (acks=1)
    - Exactly once (idempotent + transactions)

#### 2.1.5. Consumer

- **Defini√ß√£o:** Cliente que l√™ mensagens dos t√≥picos
- **Modelo de consumo:**
    - Pull-based (n√£o push)
    - Offset tracking
    - Consumer groups para escalabilidade
- **Processo de leitura:**
    1. Subscribe/assign parti√ß√µes
    2. Poll loop
    3. Processar mensagens
    4. Commit offsets
- **Padr√µes de consumo:**
    - Sequential processing
    - Parallel processing
    - Batch processing

#### 2.1.6. ZooKeeper (e KRaft)

- **ZooKeeper - Papel tradicional:**
    - Metadata management
    - Controller election
    - Configuration management
    - Cluster membership
    - ACLs storage
- **Limita√ß√µes do ZooKeeper:**
    - Componente externo adicional
    - Complexidade operacional
    - Limite de escalabilidade
- **KRaft (Kafka Raft) - Novo modelo:**
    - Metadata gerenciado internamente
    - Protocolo Raft para consenso
    - Elimina√ß√£o de depend√™ncia externa
    - Melhor escalabilidade
    - Migra√ß√£o: ZooKeeper ‚Üí KRaft

### 2.2. Como o Kafka Funciona

#### 2.2.1. Sistema de Pub/Sub

- **Modelo de comunica√ß√£o:**
    - Producers publicam sem conhecer consumers
    - Consumers subscrevem sem conhecer producers
    - Desacoplamento total
- **Topic como canal:**
    - M√∫ltiplos producers por t√≥pico
    - M√∫ltiplos consumers por t√≥pico
    - Broadcasting e unicasting
- **Durabilidade:**
    - Mensagens persistidas em disco
    - Retention configur√°vel
    - Replay capability

#### 2.2.2. Processamento Ass√≠ncrono

- **Benef√≠cios:**
    - N√£o-bloqueante
    - Melhor utiliza√ß√£o de recursos
    - Toler√¢ncia a falhas tempor√°rias
- **Implementa√ß√£o:**
    - Producer callbacks
    - Consumer poll model
    - Batch processing
- **Patterns:**
    - Fire-and-forget
    - Request-reply (com correlation ID)
    - Event sourcing

### 2.3. Replica√ß√£o e Toler√¢ncia a Falhas

- **Replication Factor:**
    - N√∫mero de c√≥pias de cada parti√ß√£o
    - Padr√£o recomendado: 3
    - Trade-off: durabilidade vs storage
- **Leader-Follower Model:**
    - Um leader por parti√ß√£o
    - Followers replicam do leader
    - Elei√ß√£o autom√°tica em falhas
- **ISR (In-Sync Replicas):**
    - Replicas sincronizadas
    - min.insync.replicas configura√ß√£o
    - Garantia de durabilidade
- **Failover:**
    - Detec√ß√£o autom√°tica de falhas
    - Elei√ß√£o de novo leader
    - Rebalanceamento de parti√ß√µes

## 3. T√≥picos no Kafka

### 3.1. O que s√£o T√≥picos

- **Conceito fundamental:**
    - Stream de registros categorizados
    - Similar a tabela em banco de dados
    - Multi-subscriber support
- **Caracter√≠sticas:**
    - Nome √∫nico por cluster
    - Configura√ß√µes independentes
    - Schema opcional (Schema Registry)
- **Cria√ß√£o e gerenciamento:**

bash

```bash
  # Criar t√≥pico
  kafka-topics.sh --create \
    --bootstrap-server localhost:9092 \
    --topic my-topic \
    --partitions 3 \
    --replication-factor 2
  
  # Listar t√≥picos
  kafka-topics.sh --list \
    --bootstrap-server localhost:9092
  
  # Descrever t√≥pico
  kafka-topics.sh --describe \
    --bootstrap-server localhost:9092 \
    --topic my-topic
```

### 3.2. Particionamento de T√≥picos

- **Estrat√©gias de particionamento:**
    - Round-robin (sem key)
    - Hash-based (com key)
    - Custom partitioner
    - Sticky partitioning (otimiza√ß√£o)
- **Considera√ß√µes de design:**
    - N√∫mero de parti√ß√µes vs throughput
    - Ordena√ß√£o por key
    - Hot partitions avoidance
- **C√°lculo de parti√ß√µes:**

```
  Target Throughput (MB/s) = T
  Producer Throughput = P
  Consumer Throughput = C
  Partitions = max(T/P, T/C)
```

- **Reparticionamento:**
    - Adicionar parti√ß√µes (sempre poss√≠vel)
    - Reduzir parti√ß√µes (n√£o suportado)
    - Impacto na ordena√ß√£o

### 3.3. Reten√ß√£o de Mensagens

- **Pol√≠ticas de reten√ß√£o:**
    - **Time-based:** retention.ms
    - **Size-based:** retention.bytes
    - **Log compaction:** cleanup.policy=compact
- **Configura√ß√µes:**

properties

```properties
  # Reten√ß√£o por tempo (7 dias)
  retention.ms=604800000
  
  # Reten√ß√£o por tamanho (1GB)
  retention.bytes=1073741824
  
  # Compacta√ß√£o
  cleanup.policy=compact
  min.cleanable.dirty.ratio=0.5
```

- **Segmenta√ß√£o:**
    - segment.bytes (default 1GB)
    - segment.ms (default 7 dias)
    - Impacto na performance

### 3.4. Replica√ß√£o de T√≥picos

- **Configura√ß√£o de replica√ß√£o:**

bash

```bash
  --replication-factor 3
  --config min.insync.replicas=2
```

- **Distribui√ß√£o de r√©plicas:**
    - Rack awareness
    - Broker distribution
    - Manual reassignment
- **Monitoramento:**
    - Under-replicated partitions
    - ISR shrink/expand
    - Leader skew

## 4. Produtores no Kafka

### 4.1. O que √© um Produtor

- **Defini√ß√£o e responsabilidades:**
    - Cliente que envia dados para Kafka
    - Serializa√ß√£o de dados
    - Escolha de parti√ß√£o
    - Retry logic
- **Ciclo de vida:**
    1. Criar producer instance
    2. Configurar propriedades
    3. Enviar mensagens
    4. Flush/close
- **APIs dispon√≠veis:**
    - Java Client (nativo)
    - librdkafka (C/C++)
    - Clients para Python, Go, .NET, etc.

### 4.2. Envio de Mensagens para T√≥picos

- **M√©todos de envio:**

java

```java
  // Fire-and-forget
  producer.send(record);
  
  // Synchronous
  RecordMetadata metadata = producer.send(record).get();
  
  // Asynchronous com callback
  producer.send(record, new Callback() {
    public void onCompletion(RecordMetadata metadata, Exception e) {
      if(e != null) {
        e.printStackTrace();
      }
    }
  });
```

- **Batching:**
    - batch.size (bytes)
    - linger.ms (tempo de espera)
    - Trade-off: lat√™ncia vs throughput
- **Compress√£o:**
    - none, gzip, snappy, lz4, zstd
    - compression.type configura√ß√£o

### 4.3. Balanceamento de Carga com Parti√ß√µes

- **Default Partitioner:**
    - Sem key: round-robin/sticky
    - Com key: hash(key) % num_partitions
- **Custom Partitioner:**

java

```java
  public class CustomPartitioner implements Partitioner {
    public int partition(String topic, Object key, byte[] keyBytes,
                        Object value, byte[] valueBytes, Cluster cluster) {
      // L√≥gica customizada
      return partition;
    }
  }
```

- **Sticky Partitioner (2.4+):**
    - Melhor batching
    - Redu√ß√£o de lat√™ncia
    - Distribui√ß√£o mais uniforme

### 4.4. Confirma√ß√µes de Envio (Acknowledgements)

- **N√≠veis de acks:**
    - **acks=0:** Sem confirma√ß√£o (fire-and-forget)
    - **acks=1:** Leader confirma
    - **acks=all (-1):** Todos ISR confirmam
- **Configura√ß√µes relacionadas:**

properties

```properties
  acks=all
  min.insync.replicas=2
  retries=2147483647
  max.in.flight.requests.per.connection=5
  enable.idempotence=true
```

- **Idempot√™ncia:**
    - Evita duplicatas em retries
    - Sequ√™ncia garantida
    - Overhead m√≠nimo

## 5. Consumidores no Kafka

### 5.1. O que √© um Consumidor

- **Defini√ß√£o:**
    - Cliente que l√™ dados do Kafka
    - Pull-based model
    - Offset tracking
- **Caracter√≠sticas:**
    - Subscribe ou assign
    - Deserializa√ß√£o de dados
    - Processing guarantees

### 5.2. Grupos de Consumidores

- **Conceito:**
    - Conjunto de consumers cooperando
    - Load balancing autom√°tico
    - Fault tolerance
- **Distribui√ß√£o de parti√ß√µes:**
    - Uma parti√ß√£o por consumer m√°ximo
    - Rebalancing autom√°tico
    - Estrat√©gias: Range, RoundRobin, Sticky, Cooperative
- **Configura√ß√£o:**

properties

```properties
  group.id=my-consumer-group
  group.instance.id=consumer-1 # Para static membership
```

### 5.3. Leitura de Mensagens

- **Poll Loop Pattern:**

java

```java
  while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
      // Processar mensagem
    }
    consumer.commitSync();
  }
```

- **Configura√ß√µes de fetch:**
    - fetch.min.bytes
    - fetch.max.wait.ms
    - max.partition.fetch.bytes
    - max.poll.records

### 5.4. Controle de Deslocamento (Offset)

- **Tipos de offset:**
    - Current offset (sendo lido)
    - Committed offset (confirmado)
    - Log-end offset (fim do log)
- **Offset reset strategies:**
    - earliest
    - latest
    - none
- **Storage:**
    - __consumer_offsets topic
    - Compacted topic

### 5.5. Commit Manual e Autom√°tico

- **Auto commit:**

properties

```properties
  enable.auto.commit=true
  auto.commit.interval.ms=5000
```

- **Manual commit:**

java

```java
  // Sync commit
  consumer.commitSync();
  
  // Async commit
  consumer.commitAsync();
  
  // Commit espec√≠fico
  consumer.commitSync(Collections.singletonMap(partition, 
    new OffsetAndMetadata(lastOffset + 1)));
```

- **Trade-offs:**
    - Auto: simples mas risco de reprocessamento
    - Manual: controle fino mas complexidade

## 6. ZooKeeper e KRaft no Kafka

### 6.1. O Papel do ZooKeeper

- **Responsabilidades tradicionais:**
    - Armazenar metadata do cluster
    - Controller election
    - Broker registration
    - Topic configuration
    - ACLs e quotas
    - Consumer offsets (vers√µes antigas)
- **Estrutura no ZooKeeper:**

```
  /kafka
    /brokers
      /ids
      /topics
    /controller
    /admin
    /config
```

### 6.2. Gerenciamento de Brokers e Parti√ß√µes

- **Registro de brokers:**
    - Ephemeral nodes
    - Heartbeat mechanism
    - Failure detection
- **Partition assignment:**
    - Leader/follower mapping
    - ISR list management
    - Reassignment operations

### 6.3. Coordena√ß√£o de Elei√ß√µes de L√≠der

- **Controller broker:**
    - Um controller por cluster
    - Gerencia todas elei√ß√µes
    - Monitora broker failures
- **Elei√ß√£o de partition leader:**
    - Preferred leader election
    - Unclean leader election
    - Min ISR requirements

### 6.4. Migra√ß√£o para KRaft

- **Benef√≠cios do KRaft:**
    - Elimina√ß√£o de depend√™ncia externa
    - Melhor escalabilidade (milh√µes de parti√ß√µes)
    - Recupera√ß√£o mais r√°pida
    - Opera√ß√£o simplificada
- **Processo de migra√ß√£o:**
    1. Upgrade para vers√£o compat√≠vel
    2. Dual-write mode
    3. Migration tools
    4. Cutover
    5. ZooKeeper removal

## 7. Processamento de Streams no Kafka

### 7.1. Introdu√ß√£o ao Kafka Streams

- **O que √©:**
    - Biblioteca Java para processamento de streams
    - Parte do Apache Kafka
    - Sem cluster separado necess√°rio
- **Caracter√≠sticas:**
    - Exactly-once semantics
    - Stateful processing
    - Windowing support
    - Interactive queries
- **Arquitetura:**
    - Stream tasks
    - Stream threads
    - State stores

### 7.2. Diferen√ßa entre Kafka Streams e Processamento Tradicional

- **Kafka Streams:**
    - Library, n√£o framework
    - Embedded em aplica√ß√£o
    - Scaling horizontal simples
    - Fault tolerance autom√°tica
- **vs Batch Processing:**
    - Continuous vs periodic
    - Low latency vs high throughput
    - Stream time vs processing time
- **vs Other Stream Processors:**
    - Simplicidade vs features
    - No cluster management
    - Tight Kafka integration

### 7.3. Opera√ß√µes de Streams

#### 7.3.1. Filtragem

java

```java
KStream<String, Order> orders = builder.stream("orders");
KStream<String, Order> largeOrders = orders.filter(
    (key, order) -> order.getAmount() > 1000
);
```

#### 7.3.2. Agrega√ß√£o

java

```java
KTable<String, Long> orderCounts = orders
    .groupByKey()
    .count(Materialized.as("order-counts-store"));

KTable<Windowed<String>, Long> windowedCounts = orders
    .groupByKey()
    .windowedBy(TimeWindows.of(Duration.ofMinutes(5)))
    .count();
```

#### 7.3.3. Jun√ß√µes de Fluxos

java

```java
// Stream-Stream Join
KStream<String, EnrichedOrder> enrichedOrders = orders.join(
    payments,
    (order, payment) -> new EnrichedOrder(order, payment),
    JoinWindows.of(Duration.ofMinutes(5))
);

// Stream-Table Join
KStream<String, CustomerOrder> customerOrders = orders.join(
    customers,
    (order, customer) -> new CustomerOrder(order, customer)
);
```

### 7.4. Windowing

- **Tipos de janelas:**
    - **Tumbling:** N√£o sobrep√µem, tamanho fixo
    - **Hopping:** Sobrep√µem, tamanho e avan√ßo fixos
    - **Sliding:** Atualizam continuamente
    - **Session:** Baseadas em inatividade
- **Implementa√ß√£o:**

java

```java
  TimeWindows.of(Duration.ofMinutes(5)) // Tumbling
  TimeWindows.of(Duration.ofMinutes(10)).advanceBy(Duration.ofMinutes(5)) // Hopping
  SessionWindows.with(Duration.ofMinutes(5)) // Session
```

### 7.5. State Stores

- **Tipos:**
    - In-memory stores
    - Persistent stores (RocksDB)
    - Window stores
- **Gerenciamento:**
    - Changelog topics
    - State restoration
    - Standby replicas
- **Interactive Queries:**

java

```java
  ReadOnlyKeyValueStore<String, Long> store = 
    streams.store("store-name", QueryableStoreTypes.keyValueStore());
```

## 8. Administra√ß√£o do Kafka

### 8.1. Instala√ß√£o e Configura√ß√£o do Kafka

#### 8.1.1. Instala√ß√£o com ZooKeeper

bash

```bash
# Download e extra√ß√£o
wget https://downloads.apache.org/kafka/3.6.0/kafka_2.13-3.6.0.tgz
tar -xzf kafka_2.13-3.6.0.tgz
cd kafka_2.13-3.6.0

# Iniciar ZooKeeper
bin/zookeeper-server-start.sh config/zookeeper.properties

# Iniciar Kafka
bin/kafka-server-start.sh config/server.properties
```

#### 8.1.2. Configura√ß√£o de Brokers

properties

```properties
# server.properties
broker.id=0
listeners=PLAINTEXT://localhost:9092
log.dirs=/var/kafka-logs
num.partitions=3
default.replication.factor=3
min.insync.replicas=2
log.retention.hours=168
log.segment.bytes=1073741824
zookeeper.connect=localhost:2181
```

### 8.2. Monitoramento e Gerenciamento

#### 8.2.1. Ferramentas de Monitoramento

- **JMX Metrics:**
    - Broker metrics
    - Producer/Consumer metrics
    - JVM metrics
- **Ferramentas:**
    - **Prometheus + Grafana:** M√©tricas e dashboards
    - **Burrow:** Consumer lag monitoring
    - **Kafka Manager/CMAK:** UI para administra√ß√£o
    - **Conduktor:** Plataforma completa
    - **AKHQ:** Web UI moderna
- **M√©tricas cr√≠ticas:**
    - Messages in/out rate
    - Byte in/out rate
    - Request rate and latency
    - ISR shrink/expand rate
    - Consumer lag

#### 8.2.2. Monitoramento de T√≥picos e Parti√ß√µes

bash

```bash
# Under-replicated partitions
kafka-topics.sh --describe --under-replicated-partitions \
  --bootstrap-server localhost:9092

# Consumer lag
kafka-consumer-groups.sh --describe \
  --group my-group \
  --bootstrap-server localhost:9092

# Partition distribution
kafka-log-dirs.sh --describe \
  --bootstrap-server localhost:9092
```

### 8.3. Seguran√ßa no Kafka

#### 8.3.1. Autentica√ß√£o com SSL/TLS

properties

```properties
# Broker config
listeners=SSL://localhost:9093
ssl.keystore.location=/var/kafka/kafka.server.keystore.jks
ssl.keystore.password=password
ssl.key.password=password
ssl.truststore.location=/var/kafka/kafka.server.truststore.jks
ssl.truststore.password=password
ssl.client.auth=required
```

#### 8.3.2. SASL Authentication

- **Mecanismos suportados:**
    - PLAIN
    - SCRAM-SHA-256/512
    - GSSAPI (Kerberos)
    - OAUTHBEARER
- **Configura√ß√£o SCRAM:**

bash

```bash
  kafka-configs.sh --bootstrap-server localhost:9092 \
    --alter --add-config 'SCRAM-SHA-256=[iterations=8192,password=alice-secret]' \
    --entity-type users --entity-name alice
```

#### 8.3.3. Controle de Acesso com ACLs

bash

```bash
# Permitir produtor
kafka-acls.sh --bootstrap-server localhost:9092 \
  --add --allow-principal User:alice \
  --operation Write --topic test-topic

# Permitir consumidor
kafka-acls.sh --bootstrap-server localhost:9092 \
  --add --allow-principal User:bob \
  --operation Read --topic test-topic \
  --group test-group
```

### 8.4. Escalabilidade

#### 8.4.1. Adi√ß√£o de Novos Brokers

1. **Preparar novo broker:**
    - Configurar broker.id √∫nico
    - Mesmo zookeeper.connect
    - Configura√ß√µes compat√≠veis
2. **Iniciar broker**
3. **Redistribuir parti√ß√µes:**

bash

```bash
   kafka-reassign-partitions.sh --generate \
     --topics-to-move-json-file topics.json \
     --broker-list "0,1,2,3"
```

#### 8.4.2. Rebalanceamento de Parti√ß√µes

- **Criar plano de reassignment:**

```json
  {
    "partitions": [
      {
        "topic": "test",
        "partition": 0,
        "replicas": [1,2,3]
      }
    ]
  }
```

- **Executar reassignment:**

bash

```bash
  kafka-reassign-partitions.sh --execute \
    --reassignment-json-file reassignment.json \
    --bootstrap-server localhost:9092
```

- **Monitorar progresso:**

bash

```bash
  kafka-reassign-partitions.sh --verify \
    --reassignment-json-file reassignment.json \
    --bootstrap-server localhost:9092
```

## 9. Integra√ß√£o do Kafka com Outros Sistemas

### 9.1. Integra√ß√£o com Apache Flink

- **Flink Kafka Connector:**

java

```java
  FlinkKafkaConsumer<String> consumer = new FlinkKafkaConsumer<>(
    "topic",
    new SimpleStringSchema(),
    properties
  );
  
  DataStream<String> stream = env.addSource(consumer);
```

- **Features:**
    - Exactly-once semantics
    - Checkpointing
    - Backpressure handling
    - Event time processing
- **Use cases:**
    - Complex event processing
    - Real-time analytics
    - Machine learning pipelines

### 9.2. Integra√ß√£o com Apache Spark

- **Spark Structured Streaming:**

scala

```scala
  val df = spark
    .readStream
    .format("kafka")
    .option("kafka.bootstrap.servers", "localhost:9092")
    .option("subscribe", "topic")
    .load()
```

- **Features:**
    - Micro-batch processing
    - SQL queries on streams
    - ML integration
- **Spark Streaming (DStream):**
    - Direct approach
    - Receiver-based approach

### 9.3. Conectores Kafka Connect

#### 9.3.1. Source Connectors

- **JDBC Source:**

json

```json
  {
    "name": "jdbc-source",
    "config": {
      "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
      "connection.url": "jdbc:postgresql://localhost/test",
      "mode": "incrementing",
      "incrementing.column.name": "id",
      "topic.prefix": "postgres-"
    }
  }
```

- **Debezium CDC:**
    - MySQL, PostgreSQL, Oracle
    - MongoDB, SQL Server
    - Real-time change capture
- **File Source:**
    - CSV, JSON, Avro
    - Directory watching

#### 9.3.2. Sink Connectors

- **Elasticsearch Sink:**

json

```json
  {
    "name": "es-sink",
    "config": {
      "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
      "connection.url": "http://localhost:9200",
      "topics": "logs",
      "type.name": "_doc"
    }
  }
```

- **S3 Sink:**
    - Partitioned by time
    - Multiple formats
    - Compression support
- **JDBC Sink:**
    - Upsert/insert modes
    - Schema evolution

### 9.4. REST Proxy e Schema Registry

- **REST Proxy:**
    - HTTP interface para Kafka
    - Produce/consume via REST
    - √ötil para linguagens sem client nativo
- **Schema Registry:**
    - Centraliza√ß√£o de schemas
    - Versionamento e evolu√ß√£o
    - Compatibilidade enforcement

## 10. T√≥picos Avan√ßados

### 10.1. Replica√ß√£o entre Data Centers

- **MirrorMaker 2.0:**
    - Active-Active replication
    - Active-Passive replication
    - Offset translation
    - Topic renaming
- **Configura√ß√£o:**

properties

```properties
  clusters = primary, backup
  primary.bootstrap.servers = primary:9092
  backup.bootstrap.servers = backup:9092
  
  primary->backup.enabled = true
  primary->backup.topics = .*
```

- **Considera√ß√µes:**
    - Network latency
    - Bandwidth costs
    - Conflict resolution

### 10.2. Compacta√ß√£o de Log

- **Conceito:**
    - Mant√©m √∫ltima mensagem por key
    - √ötil para snapshots e caches
    - Reduz storage
- **Configura√ß√£o:**

properties

```properties
  cleanup.policy=compact
  min.cleanable.dirty.ratio=0.5
  segment.ms=604800000
  delete.retention.ms=86400000
```

- **Use cases:**
    - Database changelogs
    - Cache materialization
    - Configuration distribution

### 10.3. Rebalanceamento de Consumidores

- **Triggers:**
    - Consumer join/leave
    - Partition count change
    - Subscription change
- **Estrat√©gias:**
    - **Range:** Parti√ß√µes consecutivas
    - **RoundRobin:** Distribui√ß√£o uniforme
    - **Sticky:** Minimiza movimento
    - **Cooperative:** Incremental rebalancing
- **Configura√ß√£o:**

properties

```properties
  partition.assignment.strategy=org.apache.kafka.clients.consumer.CooperativeStickyAssignor
  session.timeout.ms=10000
  max.poll.interval.ms=300000
```

### 10.4. Kafka Streams vs. Apache Flink

|Aspecto|Kafka Streams|Apache Flink|
|---|---|---|
|Deployment|Library (embedded)|Cluster|
|Complexity|Simples|Complexo|
|Features|B√°sico-intermedi√°rio|Avan√ßado|
|Latency|Low ms|Sub-ms|
|State Management|RocksDB|Pluggable|
|SQL Support|KSQL (separado)|Table API nativo|
|Use Cases|Microservi√ßos, apps m√©dias|Big data, ML, CEP|

### 10.5. Otimiza√ß√£o de Desempenho

#### 10.5.1. Configura√ß√µes de T√≥picos

properties

```properties
# Otimiza√ß√µes de performance
compression.type=lz4
segment.bytes=1073741824
min.insync.replicas=2
unclean.leader.election.enable=false

# Otimiza√ß√µes para throughput
batch.size=32768
linger.ms=5
buffer.memory=33554432
```

#### 10.5.2. Tuning de Produtores e Consumidores

- **Producer tuning:**

properties

```properties
  # Throughput
  batch.size=65536
  linger.ms=10
  compression.type=lz4
  buffer.memory=67108864
  
  # Lat√™ncia
  batch.size=0
  linger.ms=0
  compression.type=none
```

- **Consumer tuning:**

properties

```properties
  # Throughput
  fetch.min.bytes=50000
  fetch.max.wait.ms=500
  max.partition.fetch.bytes=1048576
  
  # Lat√™ncia
  fetch.min.bytes=1
  fetch.max.wait.ms=0
```

### 10.6. Transa√ß√µes

- **Producer transactions:**

java

```java
  producer.initTransactions();
  try {
    producer.beginTransaction();
    producer.send(record1);
    producer.send(record2);
    producer.commitTransaction();
  } catch (Exception e) {
    producer.abortTransaction();
  }
```

- **Consumer configuration:**

properties

```properties
  isolation.level=read_committed
  enable.auto.commit=false
```

- **Exactly-once semantics:**
    - Idempotent producers
    - Transactional messaging
    - Stream processing guarantees

## 11. Casos de Uso e Boas Pr√°ticas

### 11.1. Event Sourcing

- **Conceito:**
    - Armazenar eventos, n√£o estado
    - Rebuild de estado a partir de eventos
    - Auditoria completa
- **Implementa√ß√£o com Kafka:**
    - Topics como event stores
    - Compacted topics para snapshots
    - Kafka Streams para proje√ß√µes
- **Exemplo pr√°tico:**

java

```java
  // Evento
  OrderCreated event = new OrderCreated(orderId, customerId, items);
  producer.send(new ProducerRecord<>("orders-events", orderId, event));
  
  // Proje√ß√£o
  KTable<String, Order> orders = ordersEvents
    .groupByKey()
    .aggregate(
      Order::new,
      (orderId, event, order) -> order.apply(event),
      Materialized.as("orders-store")
    );
```

### 11.2. CQRS (Command Query Responsibility Segregation)

- **Arquitetura:**
    - Commands via Kafka
    - Query models via projections
    - Eventual consistency
- **Implementa√ß√£o:**
    - Command topics
    - Event topics
    - View materialization com Kafka Streams/Connect
- **Benef√≠cios:**
    - Escalabilidade independente
    - Modelos otimizados
    - Flexibilidade

### 11.3. Processamento em Tempo Real

- **Patterns:**
    - Stream enrichment
    - Windowed aggregations
    - Pattern detection
    - Alerting
- **Exemplos:**
    - Detec√ß√£o de fraude
    - Monitoramento de IoT
    - Real-time dashboards
    - Recomenda√ß√µes

### 11.4. Boas Pr√°ticas de Desenvolvimento com Kafka

- **Design de topics:**
    - Um t√≥pico por tipo de evento
    - Naming consistente: `<namespace>.<entity>.<event>`
    - Evitar topics muito granulares
- **Mensagens:**
    - Use schemas (Avro/Protobuf)
    - Inclua metadata em headers
    - Keys significativas para ordena√ß√£o
- **Error handling:**
    - Dead letter queues
    - Retry topics
    - Circuit breakers
- **Testing:**
    - EmbeddedKafka para testes
    - Testcontainers
    - Consumer lag simulation

### 11.5. Boas Pr√°ticas de Administra√ß√£o e Escalabilidade

- **Capacity planning:**

```
  Storage = (msg/day √ó size √ó retention √ó RF) / compression
  Network = peak msg/sec √ó size √ó (RF + consumers)
```

- **Monitoramento essencial:**
    - Under-replicated partitions = 0
    - Consumer lag crescente
    - Disk usage < 85%
    - Network utilization < 80%
- **Deployment:**
    - Automatiza√ß√£o com IaC (Terraform)
    - GitOps para configura√ß√µes
    - Blue-green deployments
- **Disaster Recovery:**
    - Backup de configura√ß√µes
    - Multi-DC replication
    - RTO/RPO definidos
    - Testes regulares de DR

## 12. Padr√µes Arquiteturais com Kafka

### 12.1. Microservi√ßos Event-Driven

- **Comunica√ß√£o ass√≠ncrona:**
    - Decoupling de servi√ßos
    - Resili√™ncia a falhas
    - Escalabilidade independente
- **Patterns:**
    - Event notification
    - Event-carried state transfer
    - Event collaboration
- **Implementa√ß√£o:**
    - Topic por agregado
    - Schema registry obrigat√≥rio
    - Consumer groups por servi√ßo

### 12.2. Saga Pattern

- **Coordena√ß√£o de transa√ß√µes distribu√≠das:**
    - Choreography-based sagas
    - Orchestration-based sagas
    - Compensating transactions
- **Implementa√ß√£o com Kafka:**

java

```java
  // Choreography
  orderService.on("OrderCreated", event -> {
    // Reserve inventory
    publish("InventoryReserved", ...);
  });
  
  paymentService.on("InventoryReserved", event -> {
    // Process payment
    publish("PaymentProcessed", ...);
  });
```

### 12.3. Data Mesh

- **Princ√≠pios:**
    - Domain ownership
    - Data as product
    - Self-serve platform
    - Federated governance
- **Kafka como backbone:**
    - Topics por dom√≠nio
    - Schema registry por dom√≠nio
    - Cross-domain events
    - Data discovery

### 12.4. Lambda Architecture

- **Camadas:**
    - Batch layer (hist√≥rico)
    - Speed layer (real-time)
    - Serving layer
- **Kafka role:**
    - Fonte √∫nica de verdade
    - Feed para batch e streaming
    - Reprocessamento capability

## 13. Cloud e Kubernetes

### 13.1. Amazon MSK (Managed Streaming for Kafka)

- **Tipos de cluster:**
    - **Provisioned:** Controle total
    - **Serverless:** Totalmente gerenciado
- **Features:**
    - Auto-scaling
    - AWS integration
    - IAM authentication
    - MSK Connect
- **Configura√ß√£o com Terraform:**

hcl

```hcl
  resource "aws_msk_cluster" "kafka" {
    cluster_name = "production-kafka"
    kafka_version = "3.6.0"
    number_of_broker_nodes = 3
    
    broker_node_group_info {
      instance_type = "kafka.m5.large"
      storage_info {
        ebs_storage_info {
          volume_size = 1000
        }
      }
    }
    
    client_authentication {
      sasl {
        iam = true
      }
    }
  }
```

### 13.2. Confluent Cloud

- **Features:**
    - Global deployment
    - 99.99% SLA
    - ksqlDB included
    - Managed connectors
- **Pricing model:**
    - Pay per use
    - Ingress/egress charges
    - Storage costs

### 13.3. Kubernetes com Strimzi

- **Operator pattern:**

yaml

```yaml
  apiVersion: kafka.strimzi.io/v1beta2
  kind: Kafka
  metadata:
    name: production-cluster
  spec:
    kafka:
      replicas: 3
      listeners:
        - name: tls
          port: 9093
          type: internal
          tls: true
      storage:
        type: persistent-claim
        size: 100Gi
      config:
        default.replication.factor: 3
        min.insync.replicas: 2
    zookeeper:
      replicas: 3
      storage:
        type: persistent-claim
        size: 10Gi
```

## 14. Troubleshooting e Debugging

### 14.1. Problemas Comuns e Solu√ß√µes

#### Consumer Lag Crescente

- **Causas:**
    - Consumer lento
    - Rebalancing frequente
    - Configura√ß√£o inadequada
- **Solu√ß√µes:**
    - Aumentar paralelismo (mais consumers)
    - Otimizar processamento
    - Ajustar session.timeout.ms
    - Verificar max.poll.records

#### Under-replicated Partitions

- **Causas:**
    - Broker down
    - Disk failure
    - Network issues
- **Solu√ß√µes:**
    - Verificar broker health
    - Aumentar replica.lag.time.max.ms
    - Forced leader election

#### Out of Memory

- **Causas:**
    - Muitas parti√ß√µes
    - Buffer overflow
    - State stores grandes
- **Solu√ß√µes:**
    - Aumentar heap size
    - Reduzir buffer.memory
    - Configurar RocksDB

### 14.2. Tools de Debugging

- **kafka-dump-log:**

bash

```bash
  kafka-dump-log.sh --files /var/kafka-logs/topic-0/00000000000000000000.log \
    --print-data-log
```

- **kafka-consumer-groups:**

bash

```bash
  # Resetar offset
  kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
    --group my-group --reset-offsets --to-earliest \
    --topic test --execute
```

- **JMX/JConsole:**
    - Heap analysis
    - Thread dumps
    - MBean inspection

## 15. Performance e Benchmarking

### 15.1. Ferramentas de Teste

bash

```bash
# Producer performance test
kafka-producer-perf-test.sh \
  --topic test \
  --num-records 1000000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props bootstrap.servers=localhost:9092

# Consumer performance test
kafka-consumer-perf-test.sh \
  --bootstrap-server localhost:9092 \
  --topic test \
  --messages 1000000
```

### 15.2. M√©tricas de Performance

- **Throughput:**
    - MB/sec in/out
    - Messages/sec
    - Records/sec per partition
- **Latency:**
    - End-to-end latency
    - Produce latency
    - Fetch latency
- **Utilization:**
    - CPU usage
    - Memory usage
    - Disk I/O
    - Network I/O

### 15.3. Otimiza√ß√µes de Hardware

- **Disk:**
    - SSD para melhor lat√™ncia
    - RAID 10 para performance
    - XFS ou ext4 filesystem
- **Network:**
    - 10 Gbps+ para produ√ß√£o
    - Dedicated network para replication
- **Memory:**
    - 32-64 GB para brokers
    - Page cache optimization
- **CPU:**
    - 8-16 cores m√≠nimo
    - Disable CPU power saving

## 16. Projetos Pr√°ticos Sugeridos

### 16.1. Sistema de Logs Distribu√≠do

- Topics por aplica√ß√£o
- Aggregation com Kafka Streams
- Sink para Elasticsearch
- Dashboard com Kibana

### 16.2. Pipeline de Data Lake

- CDC com Debezium
- Transforma√ß√£o com Kafka Streams
- Sink para S3/HDFS
- Cataloga√ß√£o com Glue/Hive

### 16.3. Sistema de Notifica√ß√µes Real-time

- Eventos de m√∫ltiplas fontes
- Rules engine
- Delivery channels (email, SMS, push)
- Tracking e analytics

### 16.4. E-commerce Event-Driven

- Order management
- Inventory tracking
- Payment processing
- Shipping coordination
- Analytics e reporting

## 17. Recursos de Estudo e Certifica√ß√£o

### 17.1. Livros Essenciais

1. **"Kafka: The Definitive Guide"** (Narkhede, Shapira, Palino)
2. **"Kafka Streams in Action"** (Bill Bejeck)
3. **"Mastering Kafka Streams and ksqlDB"** (Mitch Seymour)
4. **"Building Event-Driven Microservices"** (Adam Bellemare)

### 17.2. Cursos e Treinamentos

- **Confluent Training:** Developer, Administrator, Streams
- **Udemy:** Apache Kafka Series (Stephane Maarek)
- **Coursera:** Big Data Analysis with Scala and Spark
- **LinkedIn Learning:** Apache Kafka Essential Training

### 17.3. Certifica√ß√µes

- **CCDAK:** Confluent Certified Developer for Apache Kafka
    - 60 quest√µes
    - 90 minutos
    - 70% para passar
- **CCAAK:** Confluent Certified Administrator for Apache Kafka
    - Foco em opera√ß√µes
    - Troubleshooting
    - Security

### 17.4. Comunidade e Eventos

- **Kafka Summit:** Confer√™ncia anual
- **Meetups locais:** Kafka User Groups
- **Online:**
    - Confluent Community Slack
    - Apache Kafka mailing lists
    - Stack Overflow
    - Reddit r/apachekafka

## 18. Roadmap de Aprendizado Recomendado

### Fase 1: Fundamentos (4 semanas)

- ‚úÖ Conceitos b√°sicos
- ‚úÖ Instala√ß√£o local
- ‚úÖ Producers/Consumers simples
- ‚úÖ Topics e parti√ß√µes

### Fase 2: Intermedi√°rio (4 semanas)

- ‚úÖ Replica√ß√£o e durabilidade
- ‚úÖ Consumer groups
- ‚úÖ Performance b√°sica
- ‚úÖ Seguran√ßa b√°sica

### Fase 3: Avan√ßado (6 semanas)

- ‚úÖ Kafka Streams
- ‚úÖ Kafka Connect
- ‚úÖ Schema Registry
- ‚úÖ Opera√ß√µes em produ√ß√£o

### Fase 4: Especializa√ß√£o (4 semanas)

- ‚úÖ Cloud deployments
- ‚úÖ Kubernetes
- ‚úÖ Patterns arquiteturais
- ‚úÖ Troubleshooting avan√ßado

### Fase 5: Maestria (Cont√≠nuo)

- ‚úÖ Contribui√ß√µes open source
- ‚úÖ Certifica√ß√µes
- ‚úÖ Projetos complexos
- ‚úÖ Mentoria e ensino