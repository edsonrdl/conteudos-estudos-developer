
Este guia explica como configurar e usar o Apache Kafka para mensageria usando Docker, incluindo exemplos prÃ¡ticos em Python.

## ğŸ“‹ SumÃ¡rio

- [O que Ã© Kafka?](https://claude.ai/chat/3dcbca0c-9f48-49b1-9497-8a14e9cc32f3#o-que-%C3%A9-kafka)
- [Conceitos Fundamentais](https://claude.ai/chat/3dcbca0c-9f48-49b1-9497-8a14e9cc32f3#conceitos-fundamentais)
- [PrÃ©-requisitos](https://claude.ai/chat/3dcbca0c-9f48-49b1-9497-8a14e9cc32f3#pr%C3%A9-requisitos)
- [ConfiguraÃ§Ã£o do Ambiente](https://claude.ai/chat/3dcbca0c-9f48-49b1-9497-8a14e9cc32f3#configura%C3%A7%C3%A3o-do-ambiente)
- [Usando os Exemplos](https://claude.ai/chat/3dcbca0c-9f48-49b1-9497-8a14e9cc32f3#usando-os-exemplos)
- [Comandos Ãšteis](https://claude.ai/chat/3dcbca0c-9f48-49b1-9497-8a14e9cc32f3#comandos-%C3%BAteis)
- [Monitoramento](https://claude.ai/chat/3dcbca0c-9f48-49b1-9497-8a14e9cc32f3#monitoramento)
- [Troubleshooting](https://claude.ai/chat/3dcbca0c-9f48-49b1-9497-8a14e9cc32f3#troubleshooting)
- [PrÃ³ximos Passos](https://claude.ai/chat/3dcbca0c-9f48-49b1-9497-8a14e9cc32f3#pr%C3%B3ximos-passos)

## O que Ã© Kafka?

Apache Kafka Ã© uma plataforma de streaming distribuÃ­da que funciona como um **sistema de mensageria pub/sub** (publish/subscribe). Ã‰ amplamente usado para:

- **Mensageria entre serviÃ§os**: ComunicaÃ§Ã£o assÃ­ncrona entre microserviÃ§os
- **Streaming de dados em tempo real**: Processamento de grandes volumes de dados
- **Log de eventos**: Armazenamento durÃ¡vel de eventos de aplicaÃ§Ã£o
- **IntegraÃ§Ã£o de sistemas**: Conectar diferentes aplicaÃ§Ãµes e banco de dados

### Por que usar Kafka?

- âœ… **Alta performance**: Pode processar milhÃµes de mensagens por segundo
- âœ… **Durabilidade**: Mensagens sÃ£o persistidas em disco
- âœ… **Escalabilidade**: FÃ¡cil de escalar horizontalmente
- âœ… **TolerÃ¢ncia a falhas**: ReplicaÃ§Ã£o automÃ¡tica dos dados
- âœ… **Tempo real**: LatÃªncia muito baixa

## Conceitos Fundamentais

### ğŸ—ï¸ **Broker**

- Ã‰ um servidor Kafka individual
- ResponsÃ¡vel por armazenar e servir as mensagens
- Em produÃ§Ã£o, vocÃª tem mÃºltiplos brokers formando um cluster

### ğŸ“‚ **Topic (TÃ³pico)**

- Ã‰ como uma "pasta" ou "canal" onde as mensagens sÃ£o organizadas
- Exemplo: `user-events`, `payment-notifications`, `system-logs`
- As mensagens sÃ£o categorizadas por tÃ³pico

### ğŸ“Š **Partition (PartiÃ§Ã£o)**

- Cada tÃ³pico Ã© dividido em partiÃ§Ãµes para permitir paralelismo
- Cada partiÃ§Ã£o Ã© uma sequÃªncia ordenada de mensagens
- Permite que mÃºltiplos consumers processem o mesmo tÃ³pico simultaneamente

### ğŸ“¤ **Producer (Produtor)**

- AplicaÃ§Ã£o que **envia** mensagens para tÃ³picos
- Decide em qual partiÃ§Ã£o a mensagem vai ser armazenada
- Exemplo: microserviÃ§o de checkout enviando eventos de compra

### ğŸ“¥ **Consumer (Consumidor)**

- AplicaÃ§Ã£o que **lÃª** mensagens de tÃ³picos
- Pode processar mensagens de uma ou mÃºltiplas partiÃ§Ãµes
- Exemplo: serviÃ§o de email lendo eventos para enviar notificaÃ§Ãµes

### ğŸ‘¥ **Consumer Group (Grupo de Consumidores)**

- Grupo de consumers que trabalham juntos para processar um tÃ³pico
- Kafka distribui as partiÃ§Ãµes entre os consumers do grupo
- Se um consumer falha, outro assume suas partiÃ§Ãµes

### ğŸ¯ **Offset**

- Ã‰ a posiÃ§Ã£o de uma mensagem dentro de uma partiÃ§Ã£o
- Como um "bookmark" que indica qual foi a Ãºltima mensagem lida
- Kafka salva automaticamente o offset para cada consumer group

### ğŸ”‘ **Key (Chave)**

- Identificador opcional de uma mensagem
- Mensagens com a mesma chave vÃ£o sempre para a mesma partiÃ§Ã£o
- Ãštil para manter ordem de eventos relacionados

### ğŸ˜ **Zookeeper**

- Sistema usado para coordenar o cluster Kafka
- Gerencia metadados dos brokers, tÃ³picos e partiÃ§Ãµes
- **Nota**: VersÃµes mais novas do Kafka estÃ£o removendo dependÃªncia do Zookeeper

## PrÃ©-requisitos

- Docker e Docker Compose instalados
- Python 3.7+ (para os exemplos)
- Pelo menos 4GB de RAM disponÃ­vel

## ConfiguraÃ§Ã£o do Ambiente

### 1. Clone e Configure

```bash
# Clone este repositÃ³rio
git clone <seu-repositorio>
cd kafka-docker-setup

# Suba o ambiente
docker-compose up -d

# Verifique se estÃ¡ rodando
docker-compose ps
```

### 2. ServiÃ§os DisponÃ­veis

ApÃ³s executar `docker-compose up -d`, vocÃª terÃ¡:

|ServiÃ§o|Porta|DescriÃ§Ã£o|
|---|---|---|
|**Zookeeper**|2181|CoordenaÃ§Ã£o do cluster|
|**Kafka Broker**|9092|Broker principal|
|**Kafka UI**|8080|Interface web para monitoramento|

### 3. Verifique se estÃ¡ funcionando

Acesse http://localhost:8080 - vocÃª deve ver a interface do Kafka UI.

## Usando os Exemplos

### InstalaÃ§Ã£o das dependÃªncias

```bash
pip install kafka-python
```

### Producer (Enviando Mensagens)

```bash
# Execute o producer
python kafka_producer.py
```

O producer vai:

- Conectar no Kafka
- Enviar mensagens de exemplo para o tÃ³pico `user-events`
- Mostrar confirmaÃ§Ãµes de entrega

### Consumer (Recebendo Mensagens)

```bash
# Execute o consumer (em outro terminal)
python kafka_consumer.py
```

O consumer vai:

- Conectar no Kafka
- Ler mensagens do tÃ³pico `user-events`
- Processar cada mensagem recebida

### Testando o Fluxo Completo

1. **Terminal 1**: Execute o consumer
2. **Terminal 2**: Execute o producer
3. **Browser**: Acesse http://localhost:8080 para monitorar

VocÃª verÃ¡ as mensagens sendo enviadas pelo producer e recebidas pelo consumer em tempo real!

## Comandos Ãšteis

### Gerenciamento de TÃ³picos

```bash
# Entrar no container do Kafka
docker exec -it kafka bash

# Criar um tÃ³pico
kafka-topics --create \
  --topic meu-topico \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1

# Listar tÃ³picos
kafka-topics --list --bootstrap-server localhost:9092

# Descrever um tÃ³pico
kafka-topics --describe --topic user-events --bootstrap-server localhost:9092

# Deletar um tÃ³pico
kafka-topics --delete --topic meu-topico --bootstrap-server localhost:9092
```

### Testando via Terminal

```bash
# Producer via terminal (digite mensagens)
kafka-console-producer --topic user-events --bootstrap-server localhost:9092

# Consumer via terminal (recebe mensagens)
kafka-console-consumer --topic user-events --from-beginning --bootstrap-server localhost:9092

# Consumer especÃ­fico de um grupo
kafka-console-consumer \
  --topic user-events \
  --group meu-grupo \
  --bootstrap-server localhost:9092
```

### Monitoramento

```bash
# Ver grupos de consumers
kafka-consumer-groups --list --bootstrap-server localhost:9092

# Detalhes de um grupo especÃ­fico
kafka-consumer-groups --describe --group my-consumer-group --bootstrap-server localhost:9092

# Logs do Kafka
docker-compose logs -f kafka

# EstatÃ­sticas de performance
docker exec -it kafka kafka-run-class kafka.tools.JmxTool --object-name kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec
```

## Monitoramento

### Kafka UI (Interface Web)

Acesse http://localhost:8080 para:

- **Topics**: Ver todos os tÃ³picos, partiÃ§Ãµes e mensagens
- **Consumers**: Monitorar grupos de consumers e lag
- **Brokers**: Status dos servidores Kafka
- **Messages**: Visualizar mensagens em tempo real

### MÃ©tricas Importantes

- **Lag**: DiferenÃ§a entre Ãºltima mensagem produzida e Ãºltima consumida
- **Throughput**: Mensagens por segundo (produzidas/consumidas)
- **Partitions**: DistribuiÃ§Ã£o de carga entre partiÃ§Ãµes
- **Replication**: Status da replicaÃ§Ã£o entre brokers

## Troubleshooting

### Problemas Comuns

#### âŒ "Connection refused" ao conectar

```bash
# Verifique se os containers estÃ£o rodando
docker-compose ps

# Verifique os logs
docker-compose logs kafka

# Reinicie os serviÃ§os
docker-compose restart
```

#### âŒ Consumer nÃ£o recebe mensagens

```bash
# Verifique se o tÃ³pico existe
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092

# Verifique o offset do consumer group
kafka-consumer-groups --describe --group SEU_GRUPO --bootstrap-server localhost:9092
```

#### âŒ Mensagens nÃ£o sÃ£o entregues

- Verifique se o producer estÃ¡ usando o servidor correto (`localhost:9092`)
- Confirme que o tÃ³pico foi criado automaticamente ou crie manualmente
- Verifique logs do broker para erros

### Limpeza do Ambiente

```bash
# Para todos os serviÃ§os
docker-compose down

# Remove volumes (CUIDADO: apaga todas as mensagens)
docker-compose down -v

# Remove imagens
docker-compose down --rmi all
```

## PrÃ³ximos Passos

### Para Aprender Mais

1. **Kafka Streams**: Para processamento de streams
2. **Schema Registry**: Para evoluÃ§Ã£o de schemas
3. **Kafka Connect**: Para integraÃ§Ã£o com bancos de dados
4. **KSQL**: Para consultas SQL em streams

### ConfiguraÃ§Ãµes de ProduÃ§Ã£o

- **MÃºltiplos Brokers**: Para alta disponibilidade
- **ReplicaÃ§Ã£o**: `replication-factor` > 1
- **Monitoramento**: Prometheus + Grafana
- **SeguranÃ§a**: SSL/SASL para autenticaÃ§Ã£o
- **Backup**: EstratÃ©gias de backup e recovery

### IntegraÃ§Ãµes Ãšteis

- **Spring Boot**: Spring Kafka para aplicaÃ§Ãµes Java
- **Node.js**: KafkaJS para aplicaÃ§Ãµes JavaScript
- **.NET**: Confluent.Kafka para aplicaÃ§Ãµes .NET
- **Go**: Sarama para aplicaÃ§Ãµes Go

---

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o Oficial do Kafka](https://kafka.apache.org/documentation/)
- [Confluent Platform](https://www.confluent.io/)
- [Kafka Streams Documentation](https://kafka.apache.org/documentation/streams/)

---

**Dica**: Comece pequeno com um tÃ³pico e alguns producers/consumers, depois gradualmente adicione complexidade conforme sua necessidade!